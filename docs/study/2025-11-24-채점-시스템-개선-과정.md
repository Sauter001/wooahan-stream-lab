# 채점 시스템 개선 과정

Stream Lab의 채점 시스템을 설계하면서 겪은 시행착오와 개선 과정을 기록한다. 단순히 구상만 하고 있던 "정답 비교" 시스템이 가 어떻게 점점 구체화되는지, 그리고 각 단계에서 어떤 통찰을 얻었는지를 기록하였다.

---

## 문제의 시작: "어떻게 채점할 것인가?"

Stream Lab은 사용자가 Stream API로 문제를 풀면 자동으로 채점하는 시스템이다. 간단해 보인다. 사용자 코드를 실행하고, 기대값과 비교하면 끝 아닌가?

하지만 막상 구현하려 하니 여러 질문이 떠올랐다:

- 기대값은 어디서 오는가?
- 테스트 데이터는 어떻게 관리하는가?
- 다양한 입력 조합을 어떻게 테스트하는가?

이 질문들에 대한 답을 찾아가는 과정이 곧 채점 시스템의 진화 과정이었다.

---

## 1차 설계: "정답 코드와 비교하자"

### 아이디어

가장 직관적인 접근이었다. 문제마다 "정답 코드"를 미리 작성해두고, 사용자 코드의 출력과 정답 코드의 출력을 비교하는 방식이다.

```java
// 정답 코드 (for문 버전)
public static List<String> filterHighScoreStudents(List<Student> students) {
    List<String> result = new ArrayList<>();
    for (Student s : students) {
        if (s.getScore() >= 80) {
            result.add(s.getName());
        }
    }
    return result;
}

// 사용자 코드 (Stream 버전)
public static List<String> filterHighScoreStudents(List<Student> students) {
    return students.stream()
            .filter(student -> student.getScore() >= 80)
            .map(Student::getName)
            .toList();
}
```

동일한 입력에 대해 두 코드가 같은 출력을 내면 정답 처리. 심플하다.

### 후보 제외 이유

구현하다 보니 근본적인 문제를 깨달았다.

> **"정답 코드가 정답이라는 보장이 없다."**

내가 작성한 정답 코드에 버그가 있으면? 경계 케이스를 놓치면? 사용자의 올바른 코드가 오답 처리될 수 있다. 이건 채점 시스템으로서 치명적이다.

또한 매 문제마다 정답 코드를 작성하고 관리해야 하는 부담도 있었다. 문제가 50개면 정답 코드도 50개. 유지보수 지옥이 예상됐다.

더 나은 방법이 필요했다.

---

## 2차 설계: "기대값을 명시하자"

### 발상의 전환

게임을 기획하면서, streamLab의 풀이과정이 흔히 프로그래머스나 leetCode에서도 나오는 SQL 풀이와 유사한 경험이라 생각되었다. 

SQL을 생각해보자. 우리는 쿼리가 올바른지 어떻게 검증하는가? 다른 쿼리와 비교하지 않는다. 특정 데이터셋에 대해 **기대하는 결과**를 정의하고, 쿼리 결과가 그와 일치하는지 확인한다.

이 아이디어를 채점 시스템에 적용했다.

```json
{
  "masterData": {
    "students": [
      { "id": 1, "name": "김철수", "score": 85 },
      { "id": 2, "name": "이영희", "score": 92 },
      { "id": 3, "name": "박민수", "score": 78 }
    ]
  },
  "problems": [
    {
      "id": "1-1-1",
      "expected": ["김철수", "이영희"]
    }
  ]
}
```

`masterData`는 마치 데이터베이스 테이블처럼 전체 데이터를 담고 있다. 각 문제는 이 데이터에 대해 기대하는 결과(`expected`)를 명시한다.

### 개선된 점

- **정답 코드 불필요**: 기대값만 정확히 정의하면 된다
- **검증 가능성**: 기대값은 사람이 직접 계산하고 검토할 수 있다
- **명확한 계약**: "이 데이터가 들어오면 이 결과가 나와야 한다"가 명시적

### 남은 문제

하지만 새로운 한계가 보였다.

> **"테스트 케이스를 추가하기 어렵다."**

모든 테스트가 전체 `masterData`를 사용한다면, 특정 상황을 테스트하기 위해 완전히 새로운 `masterData`를 만들어야 한다. 예를 들어 "빈 리스트", "모두 80점 이상", "모두 80점 미만" 같은 엣지 케이스를 테스트하려면?

`masterData`를 복제하고 수정하는 것은 데이터 중복과 유지보수 악몽을 부른다.

---

## 3차 설계: "inputIds로 데이터를 선택하자"

### 핵심 통찰

문제를 다시 생각해봤다. 전체 데이터 중 **일부만 선택**해서 테스트할 수 있다면?

마치 SQL에서 `WHERE id IN (1, 2, 3)`처럼, 테스트마다 원하는 레코드만 골라 사용하는 것이다.

```json
{
  "masterData": {
    "students": [
      { "id": 1, "name": "김철수", "score": 85 },
      { "id": 2, "name": "이영희", "score": 92 },
      { "id": 3, "name": "박민수", "score": 78 },
      { "id": 4, "name": "최지우", "score": 95 },
      { "id": 5, "name": "강호진", "score": 70 }
    ]
  },
  "problems": [
    {
      "id": "1-1-1",
      "testCases": [
        {
          "inputIds": [1, 2, 3],
          "expected": ["김철수", "이영희"]
        },
        {
          "inputIds": [3, 5],
          "expected": []
        },
        {
          "inputIds": [1, 2, 4],
          "expected": ["김철수", "이영희", "최지우"]
        }
      ]
    }
  ]
}
```

### 무엇이 달라졌나

**1. 하나의 masterData로 다양한 테스트 케이스 커버 가능**

데이터 중복 없이 다양한 시나리오를 테스트할 수 있다. `inputIds`만 다르게 조합하면 된다.

**2. 엣지 케이스 테스트가 쉬워졌다**

- 빈 결과: 80점 미만인 학생들만 선택
- 전부 포함: 모두 80점 이상인 학생들만 선택
- 혼합 케이스: 다양한 점수대의 학생 조합

등등 여러 조합이 가능해진다. 

**3. 문제 추가가 간편해졌다**

기존 `masterData`를 재사용하면서 새 `testCases`만 추가하면 된다. 데이터 관리 부담이 크게 줄었다.

**4. 명시적인 입출력 관계**

각 테스트 케이스가 "이 ID들이 입력이고, 이것이 출력이다"를 명확히 보여준다. 디버깅도 쉬워졌다.

---

## 설계 과정에서 배운 것

### 1. 처음부터 완벽한 설계는 없다

1차 → 2차 → 3차로 점진적으로 개선했다. 각 단계에서 실제로 구현해보고 한계를 느껴야 다음 아이디어가 떠올랐다. 이론적으로 "이게 문제가 될 것 같다"고 예상한 것보다, 직접 부딪힌 문제가 훨씬 구체적이었다.

### 2. 데이터와 로직을 분리하라

1차 설계의 문제는 "정답 로직"에 의존했다는 것이다. 로직은 버그가 있을 수 있다. 반면 데이터(`expected`)는 검증하기 쉽다. 가능하면 로직보다 데이터로 문제를 정의하는 것이 안전하다.

### 3. 유연성은 구조에서 온다

3차 설계가 유연한 이유는 `inputIds`라는 간접층을 도입했기 때문이다. 전체 데이터를 직접 사용하는 대신, ID를 통해 참조함으로써 조합의 자유도가 생겼다.

### 4. 익숙한 것에서 아이디어 얻기

`masterData`는 테이블, `inputIds`는 `WHERE IN`, `expected`는 기대 결과. 친숙한 SQL 패턴을 차용하니 설계가 자연스러워졌고, 다른 사람에게 설명하기도 쉬워졌다.

---

## 마치며

채점 시스템이 다른 stream API 연습 애플리케이션과 다른 Stream Lab의 핵심이다. 사용자 경험은 채점이 얼마나 정확하고 빠른지에 달려 있다. 세 번의 반복을 거치며 지금의 구조에 도달했지만, 여전히 개선할 여지가 있다.

앞으로 고려할 것들:
- 더 복잡한 도메인 관계 (다대다 연결)
- 순서 무관 비교가 필요한 경우
- 성능 테스트 (시간 제한)

좋은 설계는 한 번에 나오지 않는다는 사실은 인지하고 있었지만. 이번 과정으로 반복하고, 실패하고, 배우는 과정이 설계임을 깨닫는 계기가 되었다.
